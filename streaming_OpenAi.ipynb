{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP8sOVH3mqfNUPDs659dzMO",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ahmed11Raza/Agentic-Ai/blob/main/streaming_OpenAi.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O2PN3EL8ZKMo",
        "outputId": "2e727625-9d15-4bfe-fd20-e40260b3ee80"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/116.9 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.9/116.9 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/129.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.3/129.3 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m119.5/119.5 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.4/44.4 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.0/72.0 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.5/62.5 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -Uq openai-agents"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nest_asyncio\n",
        "nest_asyncio.apply()"
      ],
      "metadata": {
        "id": "ZcMTPw3NZr45"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from agents import Agent, Runner, AsyncOpenAI, OpenAIChatCompletionsModel\n",
        "from agents.run import RunConfig\n",
        "from google.colab import userdata\n",
        "\n",
        "from agents import (\n",
        "    Agent,\n",
        "    Runner,\n",
        "    set_default_openai_api,\n",
        "    set_default_openai_client,\n",
        "    set_tracing_disabled,\n",
        ")\n",
        "\n",
        "gemini_api_key = userdata.get(\"GEMINI_API_KEY\")\n",
        "\n",
        "\n",
        "# Check if the API key is present; if not, raise an error\n",
        "if not gemini_api_key:\n",
        "    raise ValueError(\"GEMINI_API_KEY is not set.\")\n",
        "\n",
        "#Reference: https://ai.google.dev/gemini-api/docs/openai\n",
        "external_client = AsyncOpenAI(\n",
        "    api_key=gemini_api_key,\n",
        "    base_url=\"https://generativelanguage.googleapis.com/v1beta/openai/\",\n",
        ")\n",
        "\n",
        "model = OpenAIChatCompletionsModel(\n",
        "    model=\"gemini-2.0-flash\",\n",
        "    openai_client=external_client\n",
        ")\n",
        "\n",
        "set_default_openai_client(client=external_client, use_for_tracing=False)\n",
        "set_default_openai_api(\"chat_completions\")\n",
        "set_tracing_disabled(disabled=True)"
      ],
      "metadata": {
        "id": "ApH-rXD9ZwqO"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import asyncio\n",
        "\n",
        "from openai.types.responses import ResponseTextDeltaEvent\n",
        "\n",
        "from agents import Agent, Runner\n",
        "\n",
        "\n",
        "async def main():\n",
        "    agent = Agent(\n",
        "        name=\"Informer\",\n",
        "        instructions=\"You are a helpful assistant.\",\n",
        "        model=model\n",
        "    )\n",
        "\n",
        "    result = Runner.run_streamed(agent, input=\"Please tell me 5 Biggest contribution in Agentic Ai.\")\n",
        "    async for event in result.stream_events():\n",
        "        if event.type == \"raw_response_event\" and isinstance(event.data, ResponseTextDeltaEvent):\n",
        "            print(event.data.delta, end=\"\", flush=True)\n",
        "\n",
        "\n",
        "\n",
        "asyncio.run(main())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lv4S_NkMZ98I",
        "outputId": "b918b75c-155c-4bce-9258-5530090f6c0c"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Okay, here are 5 of the biggest contributions in the field of Agentic AI, focusing on advancements that have significantly propelled the field forward:\n",
            "\n",
            "1.  **Large Language Models (LLMs) as Reasoning Engines:**  The ability of LLMs like GPT-4, Gemini, and others to perform complex reasoning, planning, and code generation has been a game-changer.  Before these models reached their current level of sophistication, creating agents that could break down complex tasks, strategize, and adapt was incredibly difficult. LLMs provide the \"brains\" for agents, allowing them to:\n",
            "\n",
            "    *   Understand natural language instructions.\n",
            "    *   Decompose goals into sub-goals.\n",
            "    *   Generate plans to achieve those sub-goals.\n",
            "    *   Reflect on their performance and adjust their strategies.\n",
            "    *   Learn from experience and improve over time.\n",
            "\n",
            "    This contribution has significantly reduced the need for hand-coded rules and logic, enabling more flexible and adaptable agent behavior.\n",
            "\n",
            "2.  **Memory and Context Management:**  Early AI agents often struggled with maintaining context over long interactions and remembering past experiences.  Significant advancements have been made in equipping agents with various forms of memory, including:\n",
            "\n",
            "    *   **Short-term memory (e.g., conversation history):**  Allows agents to remember recent interactions and maintain coherence.\n",
            "    *   **Long-term memory (e.g., knowledge graphs, vector databases):**  Enables agents to store and retrieve relevant information from past experiences, learned knowledge, and external sources.\n",
            "    *   **Reflection mechanisms:** Allows agents to analyze and learn from past experiences, improving future decision-making.\n",
            "\n",
            "    These memory systems allow agents to reason more effectively, learn from their mistakes, and adapt to changing circumstances.  Without robust memory, agents would be stuck in a perpetual state of reacting to the immediate present.\n",
            "\n",
            "3.  **Tool Use and API Integration:**  A key aspect of agentic AI is the ability to interact with the real world and access external information.  The development of techniques for agents to use tools and APIs has been crucial. This involves:\n",
            "\n",
            "    *   **Discovering available tools:** Agents need to identify and understand the functions of available tools (e.g., search engines, calculators, calendars, email clients, specialized databases).\n",
            "    *   **Selecting the appropriate tool:**  Agents must choose the right tool for a given task based on their understanding of the tool's capabilities and the task's requirements.\n",
            "    *   **Using tools effectively:** Agents need to format requests and interpret responses from tools correctly.\n",
            "\n",
            "    Frameworks like LangChain and LlamaIndex significantly simplify integrating tools and APIs into agent workflows, making it easier to build agents that can perform complex tasks by orchestrating different services.\n",
            "\n",
            "4.  **Reinforcement Learning and Self-Improvement:**  Reinforcement learning (RL) provides a framework for training agents to optimize their behavior through trial and error. Recent advances in RL, combined with LLMs, have enabled agents to:\n",
            "\n",
            "    *   **Learn from interactions with their environment:** Agents receive rewards or penalties based on their actions and adjust their strategies to maximize their cumulative reward.\n",
            "    *   **Develop complex skills:** RL can be used to train agents to perform tasks that are difficult to program explicitly, such as playing games, controlling robots, or optimizing complex processes.\n",
            "    *   **Adapt to changing conditions:** RL allows agents to continuously learn and improve their performance as their environment changes.\n",
            "\n",
            "    Furthermore, techniques like self-play and imitation learning have enabled agents to learn from their own experiences and from the behavior of other agents, accelerating the learning process.\n",
            "\n",
            "5.  **Frameworks and Infrastructure for Agent Development:** The emergence of open-source frameworks and platforms specifically designed for building and deploying AI agents has democratized the field.  These frameworks (e.g., LangChain, AutoGen, LlamaIndex, CrewAI) provide:\n",
            "\n",
            "    *   **Abstractions for common agent components:**  They offer pre-built modules for memory, planning, tool use, and other essential functionalities.\n",
            "    *   **Standardized interfaces:**  They simplify the integration of different LLMs, tools, and data sources.\n",
            "    *   **Development tools and debugging support:** They make it easier to build, test, and deploy AI agents.\n",
            "\n",
            "    These frameworks significantly reduce the barrier to entry for researchers and developers, fostering innovation and accelerating the development of agentic AI applications. They handle much of the \"plumbing\" allowing developers to focus on the unique logic and capabilities of their agents.\n",
            "\n",
            "In summary, these five contributions – LLMs as reasoning engines, memory and context management, tool use and API integration, reinforcement learning and self-improvement, and agent development frameworks – have been instrumental in advancing the field of agentic AI, enabling the creation of more capable, adaptable, and useful AI agents.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import asyncio\n",
        "import random\n",
        "\n",
        "from agents import Agent, ItemHelpers, Runner, function_tool\n",
        "\n",
        "\n",
        "@function_tool\n",
        "def how_many_contributions() -> int:\n",
        "    return random.randint(1, 10)\n",
        "\n",
        "\n",
        "async def main():\n",
        "    agent = Agent(\n",
        "        name=\"Informer\",\n",
        "        instructions=\"First call the `how_many_contributions` tool, then tell that more information.\",\n",
        "        tools=[how_many_contributions],\n",
        "        model=model\n",
        "    )\n",
        "\n",
        "    result = Runner.run_streamed(\n",
        "        agent,\n",
        "        input=\"Hello\",\n",
        "\n",
        "    )\n",
        "    print(\"=== Run starting ===\")\n",
        "    async for event in result.stream_events():\n",
        "        # We'll ignore the raw responses event deltas\n",
        "        if event.type == \"raw_response_event\":\n",
        "            continue\n",
        "        elif event.type == \"agent_updated_stream_event\":\n",
        "            print(f\"Agent updated: {event.new_agent.name}\")\n",
        "            continue\n",
        "        elif event.type == \"run_item_stream_event\":\n",
        "            if event.item.type == \"tool_call_item\":\n",
        "                print(\"-- Tool was called\")\n",
        "            elif event.item.type == \"tool_call_output_item\":\n",
        "                print(f\"-- Tool output: {event.item.output}\")\n",
        "            elif event.item.type == \"message_output_item\":\n",
        "                print(f\"-- Message output:\\n {ItemHelpers.text_message_output(event.item)}\")\n",
        "            else:\n",
        "                pass  # Ignore other event types\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "asyncio.run(main())\n",
        "\n",
        "print(\"=== Run complete ===\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2z3itN-XaRCo",
        "outputId": "f896447c-c572-4a13-8583-d127021d26e1"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Run starting ===\n",
            "Agent updated: Informer\n",
            "-- Tool was called\n",
            "-- Tool output: 6\n",
            "-- Message output:\n",
            " Okay, I have some information. The tool indicates there are 6 contributions.\n",
            "\n",
            "=== Run complete ===\n"
          ]
        }
      ]
    }
  ]
}